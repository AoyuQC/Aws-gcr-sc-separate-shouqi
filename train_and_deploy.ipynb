{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#安装 libsndfile\n",
    "'''\n",
    "cd /home/ec2-user/SageMaker/shouqi/libsndfile-1.0.28\n",
    "./configure --prefix=/usr    \\\n",
    "            --disable-static \\\n",
    "            --docdir=/usr/share/doc/libsndfile-1.0.28 &&\n",
    "make && sudo make install\n",
    "'''\n",
    "# !pip install asteroid -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "# !pip install librosa==0.7.2 -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import sagemaker\n",
    "import torch\n",
    "from sagemaker import get_execution_role\n",
    "from helper.utils import *\n",
    "import argparse\n",
    "import librosa\n",
    "import torch\n",
    "from scipy.signal import lfilter\n",
    "import numpy as np\n",
    "import scipy.io.wavfile\n",
    "import soundfile as sf\n",
    "import fnmatch, os, warnings\n",
    "import json\n",
    "from code.pred_utils import *\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "_role = get_execution_role()\n",
    "\n",
    "s3_path='s3://sagemaker-cn-northwest-1-969422986683/shouqi' #上传路径\n",
    "sample_rate=16000 #采样率\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 准备数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: train_sample_v6/tr/mix_both.json to s3://sagemaker-cn-northwest-1-969422986683/shouqi/separate/train/mix_both.json\n",
      "upload: train_sample_v6/tr/s2.json to s3://sagemaker-cn-northwest-1-969422986683/shouqi/separate/train/s2.json\n",
      "upload: train_sample_v6/tr/s1.json to s3://sagemaker-cn-northwest-1-969422986683/shouqi/separate/train/s1.json\n",
      "upload: train_sample_v6/cv/mix_both.json to s3://sagemaker-cn-northwest-1-969422986683/shouqi/separate/test/mix_both.json\n",
      "upload: train_sample_v6/cv/s1.json to s3://sagemaker-cn-northwest-1-969422986683/shouqi/separate/test/s1.json\n",
      "upload: train_sample_v6/cv/s2.json to s3://sagemaker-cn-northwest-1-969422986683/shouqi/separate/test/s2.json\n"
     ]
    }
   ],
   "source": [
    "def generate_data(in_dir,out_dir,out_filename,ttype): #生成array以及meta_json\n",
    "    file_infos = []\n",
    "    in_dir = os.path.abspath(in_dir)\n",
    "    wav_list = os.listdir(in_dir)\n",
    "    for wav_file in wav_list:\n",
    "        if not wav_file.endswith('.wav'):\n",
    "            continue\n",
    "        wav_path = os.path.join(in_dir, wav_file)\n",
    "        samples, _ = librosa.load(wav_path, sr=sample_rate)\n",
    "        fake_wav_path = os.path.join('/opt/ml/input/data', ttype, out_filename, wav_file)\n",
    "        file_infos.append((fake_wav_path, len(samples)))\n",
    "    if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)\n",
    "    with open(os.path.join(out_dir, out_filename + '.json'), 'w') as f:\n",
    "        json.dump(file_infos, f, indent=4)\n",
    "        \n",
    "generate_data('train_sample_v6/tr/mix_both','train_sample_v6/tr','mix_both','train')\n",
    "generate_data('train_sample_v6/tr/s1','train_sample_v6/tr','s1','train')\n",
    "generate_data('train_sample_v6/tr/s2','train_sample_v6/tr','s2','train')\n",
    "generate_data('train_sample_v6/cv/mix_both','train_sample_v6/cv','mix_both','test')\n",
    "generate_data('train_sample_v6/cv/s1','train_sample_v6/cv','s1','test')\n",
    "generate_data('train_sample_v6/cv/s2','train_sample_v6/cv','s2','test')\n",
    "\n",
    "\n",
    "!aws s3 sync train_sample_v6/tr/ $s3_path/separate/train\n",
    "!aws s3 sync train_sample_v6/cv/ $s3_path/separate/test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 开始训练和部署流程\n",
    "### 设置训练和验证数据路径"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs=\"{}/separate/train/\".format(s3_path)\n",
    "test_inputs=\"{}/separate/test/\".format(s3_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 利用sagemaker pytorch进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-16 13:40:24 Starting - Starting the training job...\n",
      "2020-08-16 13:40:27 Starting - Launching requested ML instances......\n",
      "2020-08-16 13:41:35 Starting - Preparing the instances for training.."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-56c022ba9ec2>\", line 13, in <module>\n",
      "    'test': test_inputs})\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\", line 497, in fit\n",
      "    self.latest_training_job.wait(logs=logs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/estimator.py\", line 1109, in wait\n",
      "    self.sagemaker_session.logs_for_job(self.job_name, wait=True, log_type=logs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/sagemaker/session.py\", line 3028, in logs_for_job\n",
      "    time.sleep(poll)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "dprnn_estimator = PyTorch(entry_point='dprnn-train-deploy.py',\n",
    "                            source_dir='code',\n",
    "                            train_instance_type='ml.p3.2xlarge',\n",
    "                            train_instance_count=1,\n",
    "                            role=_role,\n",
    "                            train_use_spot_instances=True, #save up to 90% training cost\n",
    "                            train_max_wait=86400,\n",
    "                            framework_version='1.5.1',\n",
    "                            hyperparameters = {'epochs': 20})\n",
    "dprnn_estimator.fit({'train': train_inputs,\n",
    "                       'test': test_inputs})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 将训练好的模型进行部署"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy my estimator to a SageMaker Endpoint and get a Predictor\n",
    "predictor = dprnn_estimator.deploy(instance_type='ml.g4dn.xlarge',\n",
    "                                     initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 或者已有训练结果,创建endpoint\n",
    "from sagemaker.pytorch.model import PyTorchModel\n",
    "import time \n",
    "\n",
    "#修改为模型路径\n",
    "model_path='s3://sagemaker-cn-northwest-1-969422986683/pytorch-training-2020-06-26-06-37-38-883/output/model.tar.gz' \n",
    "model_name='shouqiDPRNN'\n",
    "\n",
    "sm_model = PyTorchModel(model_data=model_path,\n",
    "                     role=_role,\n",
    "                     name=model_name,\n",
    "                        source_dir='code',\n",
    "                    entry_point='code/dprnn-train-deploy.py',\n",
    "                     py_version=\"py3\",\n",
    "                     framework_version=\"1.3.0\",\n",
    "                     sagemaker_session=sagemaker_session)\n",
    "endpoint_name = f'endpoint-{model_name}-' \\\n",
    "                    + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "predictor = sm_model.deploy(endpoint_name=endpoint_name,\n",
    "                         instance_type='ml.g4dn.xlarge',\n",
    "                         initial_instance_count=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#或者已有endpoint restore predictor\n",
    "import sagemaker\n",
    "from sagemaker.pytorch.model import PyTorchPredictor\n",
    "\n",
    "#修改为endpoint_name\n",
    "endpoint_name='endpoint-shouqiDPRNN-2020-08-16-07-42-14'\n",
    "predictor=PyTorchPredictor(endpoint_name, sagemaker_session=sagemaker_session)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 在部署好的模型上进行推理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 1.58 ms, total: 1.58 ms\n",
      "Wall time: 2.4 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(160000,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "instance_time = 10\n",
    "\n",
    "filename = './test.wav'\n",
    "\n",
    "def wav_clip(filename,instance_time=instance_time,sample_rate=sample_rate):\n",
    "    T = instance_time*sample_rate\n",
    "    fs, x = scipy.io.wavfile.read(filename)\n",
    "    emp = np.zeros(T)\n",
    "    if x.shape[0]<=T:\n",
    "        emp[:x.shape[0]] = x\n",
    "        return emp\n",
    "    else:\n",
    "        return x[:T]\n",
    "    \n",
    "x=wav_clip(filename)\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 0/811 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 1/811 [00:00<04:00,  3.37it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 2/811 [00:00<03:29,  3.85it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 3/811 [00:00<03:06,  4.34it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  0%|          | 4/811 [00:00<02:50,  4.74it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 5/811 [00:00<02:37,  5.11it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 6/811 [00:01<02:29,  5.39it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 7/811 [00:01<02:23,  5.61it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 8/811 [00:01<02:19,  5.76it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 9/811 [00:01<02:21,  5.69it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|          | 10/811 [00:01<02:17,  5.81it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▏         | 11/811 [00:01<02:16,  5.87it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  1%|▏         | 12/811 [00:02<02:14,  5.95it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 13/811 [00:02<02:12,  6.00it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 14/811 [00:02<02:12,  6.03it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 15/811 [00:02<02:11,  6.07it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 16/811 [00:02<02:10,  6.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 17/811 [00:02<02:10,  6.10it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 18/811 [00:03<02:08,  6.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 19/811 [00:03<02:09,  6.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  2%|▏         | 20/811 [00:03<02:08,  6.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 21/811 [00:03<02:08,  6.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 22/811 [00:03<02:07,  6.19it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 23/811 [00:03<02:07,  6.20it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 24/811 [00:04<02:07,  6.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 25/811 [00:04<02:07,  6.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 26/811 [00:04<02:07,  6.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 27/811 [00:04<02:07,  6.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  3%|▎         | 28/811 [00:04<02:07,  6.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|▎         | 29/811 [00:04<02:07,  6.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|▎         | 30/811 [00:05<02:06,  6.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 31/811 [00:05<02:06,  6.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 32/811 [00:05<02:06,  6.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 33/811 [00:05<02:05,  6.18it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 34/811 [00:05<02:06,  6.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 35/811 [00:05<02:06,  6.14it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  4%|▍         | 36/811 [00:06<02:06,  6.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▍         | 37/811 [00:06<02:05,  6.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▍         | 38/811 [00:06<02:05,  6.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▍         | 39/811 [00:06<02:05,  6.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▍         | 40/811 [00:06<02:05,  6.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 41/811 [00:06<02:05,  6.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 42/811 [00:06<02:05,  6.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 43/811 [00:07<02:04,  6.17it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  5%|▌         | 44/811 [00:07<02:04,  6.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 45/811 [00:07<02:04,  6.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 46/811 [00:07<02:04,  6.15it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 47/811 [00:07<02:04,  6.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 48/811 [00:07<02:03,  6.16it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 49/811 [00:08<02:04,  6.12it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▌         | 50/811 [00:08<02:04,  6.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▋         | 51/811 [00:08<02:04,  6.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "  6%|▋         | 52/811 [00:08<02:03,  6.13it/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "class RawWavDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    def __init__(self, filename, fs=16000, frame_size=1600):\n",
    "        input_np_arr, _ = preprocess_wav(filename, fs = fs)       \n",
    "        self.data = librosa.util.frame(input_np_arr, \n",
    "                                       frame_length=frame_size, \n",
    "                                       hop_length=frame_size, \n",
    "                                       axis=0)\n",
    "        self.nframes = len(self.data)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.nframes\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.as_tensor(self.data[idx])\n",
    "\n",
    "filename = '300_AUDIO.wav'\n",
    "# filename = 'test.wav'\n",
    "BATCH_SIZE = 8\n",
    "num_workers = 2\n",
    "\n",
    "def collate(batches):\n",
    "    lengths = torch.tensor([len(item) for item in batches])\n",
    "    # perform padding and convert to tensor\n",
    "    return pad_list(batches, 0), lengths\n",
    "\n",
    "dloader = torch.utils.data.DataLoader(RawWavDataset(filename), \n",
    "                                      batch_size=BATCH_SIZE, \n",
    "                                      num_workers=num_workers,\n",
    "                                      collate_fn = collate)\n",
    "\n",
    "\n",
    "def separate_process(xs, predictor, mix_lengths):\n",
    "    # Forward\n",
    "    response = predictor.predict(xs)#mixture_np\n",
    "    response = torch.from_numpy(response).cpu() \n",
    "    # Remove padding and flat\n",
    "    flat_estimate = remove_pad(response, mix_lengths)\n",
    "    return flat_estimate\n",
    "\n",
    "s1,s2 = [],[]\n",
    "for batch, length in tqdm(dloader):\n",
    "    est = separate_process(batch, predictor, length)\n",
    "    for b in range(len(est)):\n",
    "        s1.extend([est[b][0]])\n",
    "        s2.extend([est[b][1]])\n",
    "\n",
    "s1 = np.concatenate(s1)\n",
    "s2 = np.concatenate(s2)\n",
    "write(s1, './complete_split_s1.wav')\n",
    "write(s2, './complete_split_s2.wav')\n",
    "print('saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 44.5 ms, sys: 25.4 ms, total: 69.8 ms\n",
      "Wall time: 192 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# !pip install librosa==0.7.2 -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "# !pip install numba==0.50.0 -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "# !pip install torchaudio==0.3.0 -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "# !pip install torch==1.3.1 -i https://pypi.tuna.tsinghua.edu.cn/simple/\n",
    "\n",
    "import librosa\n",
    "from tqdm import tqdm\n",
    "from helper.utils import *\n",
    "from code.pred_utils import *\n",
    "\n",
    "\n",
    "def preprocess_wav(filename, fs = 16000):\n",
    "    x, fs = librosa.load(filename, sr =fs)\n",
    "    x_mirror = x\n",
    "    asl_level = -26.0\n",
    "    y = x + x_mirror\n",
    "#     y = y/10**(asl_meter(y, fs)/20) * 10**(asl_level/20)\n",
    "    return y, fs\n",
    "\n",
    "\n",
    "def pad_list(xs, pad_value):\n",
    "    n_batch = len(xs)\n",
    "    max_len = max(x.size(0) for x in xs)\n",
    "    pad = xs[0].new(n_batch, max_len, * xs[0].size()[1:]).fill_(pad_value)\n",
    "    for i in range(n_batch):\n",
    "        pad[i, :xs[i].size(0)] = xs[i]\n",
    "    return pad\n",
    "\n",
    "def remove_pad(inputs, inputs_lengths):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        inputs: torch.Tensor, [B, C, T] or [B, T], B is batch size\n",
    "        inputs_lengths: torch.Tensor, [B]\n",
    "    Returns:\n",
    "        results: a list containing B items, each item is [C, T], T varies\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    dim = inputs.dim()\n",
    "    if dim == 3:\n",
    "        C = inputs.size(1)\n",
    "    for input, length in zip(inputs, inputs_lengths):\n",
    "        if dim == 3: # [B, C, T]\n",
    "            results.append(input[:,:length].view(C, -1).cpu().numpy())\n",
    "        elif dim == 2:  # [B, T]\n",
    "            results.append(input[:length].view(-1).cpu().numpy())\n",
    "    return results\n",
    "\n",
    "def separate_process(xs, predictor):\n",
    "    # perform padding and convert to tensor\n",
    "    mixtures_pad = pad_list(xs, 0)\n",
    "    \n",
    "    mix_lengths = torch.tensor([len(item) for item in xs]) #torch.tensor([len(a) for a in xs])\n",
    "    # Forward\n",
    "    response = predictor.predict(mixtures_pad)#mixture_np\n",
    "    response = torch.from_numpy(response).cpu() \n",
    "    # Remove padding and flat\n",
    "    flat_estimate = remove_pad(response, mix_lengths)\n",
    "    return flat_estimate\n",
    "\n",
    "filename = '300_AUDIO.wav' #(10376000,)\n",
    "# filename = 'test.wav' #(10376000,)\n",
    "\n",
    "instance_time = 1\n",
    "\n",
    "x, fs = preprocess_wav(filename)\n",
    "\n",
    "s_x = instance_time * fs\n",
    "\n",
    "def batchify(input_np_arr, n = 8, frame_size = s_x):\n",
    "    batch = []\n",
    "    framed = librosa.util.frame(input_np_arr, frame_length=frame_size, hop_length=frame_size, axis=0)\n",
    "    for i, fr in enumerate(framed):\n",
    "        batch.append(torch.from_numpy(fr).float())\n",
    "        if (i+1) % n == 0:\n",
    "            yield batch\n",
    "            batch = []\n",
    "    if len(batch) > 0:\n",
    "        yield batch\n",
    "        \n",
    "    \n",
    "# s1 = []\n",
    "# s2 = []\n",
    "# for batch in tqdm(batchify(x)):\n",
    "#     est = separate_process(batch, predictor)\n",
    "#     for b in range(len(est)):\n",
    "#         s1.extend([est[b][0]])\n",
    "#         s2.extend([est[b][1]])\n",
    "\n",
    "# s1 = np.concatenate(s1)\n",
    "# s2 = np.concatenate(s2)\n",
    "# write(s1, './complete_split_s1.wav')\n",
    "# write(s2, './complete_split_s2.wav')\n",
    "# print('saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sagemaker_session.delete_endpoint(predictor.endpoint)\n",
    "x.shape\n",
    "# for start in range(0, l_x-s_x, s_x):\n",
    "    \n",
    "#     flat_estimate = separate_process(x[start:start+s_x], predictor)\n",
    "#     s1 = np.concatenate([s1, flat_estimate[0]])\n",
    "#     s2 = np.concatenate([s2, flat_estimate[1]])\n",
    "#     gl_i = start+s_x\n",
    "    \n",
    "    \n",
    "# if gl_i < l_x:\n",
    "#     flat_estimate = separate_process(x[gl_i:], predictor)\n",
    "#     s1 = np.concatenate([s1, flat_estimate[0]])\n",
    "#     s2 = np.concatenate([s2, flat_estimate[1]])\n",
    "# write(s1, './complete_split_s1.wav')\n",
    "# write(s2, './complete_split_s2.wav')\n",
    "# print('saved')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
